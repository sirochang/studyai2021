# 概要
「機械学習」について章ごとに要点をまとめる。

# 序章
機械学習モデリングプロセスは下記の通りで、実業務であれば前半の1~3にコストがかかる。
1. 問題設定：機械学習を使う必要があるか、ルールベースを用いて解決できないかなど
2. データ選定：機械学習のモデルを作成する上で適したデータになっているか、データに偏りやバイアスがかかっていないかなど
3. データの前処理：欠損値や異常値などを除外したり修正する
4. 機械学習モデルの選定→教師あり学習と教師なし学習でそれぞれ代表的な選定方法を学習する
5. モデルの学習（パラメータの推定）→教師あり学習と教師なし学習でそれぞれ代表的な推定方法を学習する
6. モデルの評価→教師あり学習の代表的な評価方法を学習する、教師なし学習は一般的にはモデルの評価は行わない

# 第1章 線形回帰モデル
* 直線（2次元）の方程式： y = A * x + B
* 平面（3次元）の方程式： x = A * x + B * y + C
* 超平面（n次元）の方程式： y = a_0 * x_0 + a_1 * x_1 + a_2 * x_2 ... a_n-1 * x_n-1  （ただしx_0 = 1）

a_0 ~ a_n-1をまとめたベクトルを**a**、x_0 ~ x_n-1をまとめたベクトルを**x**とすると
n次元の方程式は**a**と**x**の内積をとった形で表される。

回帰問題とは「ある入力(離散あるいは連続値)から出力(連続値)を予測する問題」である。

回帰を使ってランキング予測のようなこともできるがあまりオススメはできない（**Vapnikの原理**；ある問題を解くとき、その問題よりも難しい問題を途中の段階で解いてはならない）

入力をm次元のベクトルとする（パラメータがm次元）。また、教師あり学習なのでn個のxとyのペアが与えられる。

超平面の方程式は1つの方程式だったが、線形回帰モデルではn個の連立方程式を解くことを考える。

連立方程式の解き方からわかるように、一般的に n>m+1 でないと解くことはできない（パラメータ数よりデータ数を多く用意する必要がある）
```
y(n,1;次元) = X(n,m+1;次元) * w(m+1,1;次元) + ε(n,1;次元）
```

データとモデル出力の二乗誤差の和である平均二乗誤差を最小するパラメータを算出する。（最小二乗法）
ただし最小二乗法は外れ値に影響を受けやすいなど欠点もあるので注意する。

式の導出。
行列関連の公式としてmatrix cookbookが参考になる。

## 実装
演習を実行したgoogle colaboratoryのURL：https://colab.research.google.com/drive/1GetzrGgiYbQIH7FpsLVGKfmWMXlbh8IK?usp=sharing

# 第2章 非線形回帰モデル
複雑なモデルを考える場合は線形回帰モデルではなく非線形回帰モデルで考える。

## 基底展開法
基底関数と呼ばれる既知の非線形関数とパラメータベクトルの線型結合を用い、未知のパラメータは線形回帰モデルと同様に最小二乗法や最尤法により推定する。
* 非線形関数により、説明変数を全て新たな空間に写像する
```
y_i = ω_0 + ω_1 * φ_i(x_i1, x_i2, ..., x_im) + ... + ω_n * φ_n(x_i1, x_i2, ..., x_im) + ε_i
```
* 写像した説明変数とパラメータベクトル同士は**線形結合**となる

yの推定量の式は線形回帰モデルの時とほぼ同じように、説明変数の行列を非線形関数の計画行列で表して書ける。

## 未学習と過学習
* 未学習：学習データに対して、十分小さな誤差が得られないモデル
* 過学習：小さな誤差は得られたけど、テスト集合誤差との差が大きいモデル

過学習の対策として、学習データの数を増やしたり不要な基底関数を削除したりする方法もあるが、実現できないこともある。別の方法として正則化項（罰則化項）を設ける方法を考える。

重みが無制限であれば、より複雑なモデルを学習できるが過学習に陥りやすい。そのため、重みに制限を設けて、その制限下でモデルを学習させる。
* L2ノルム（Ridge推定量）：縮小推定、パラメータを0に近づけるよう推定
* L1ノルム（Lasso推定量）：スパース推定、いくつかのパラメータを0に推定

## 汎化性能
学習データだけではなく、未知のデータに対する予測性能。学習データとは別に用意した検証データを用いて検証する。

バイアスとバリアンスはトレードオフであり、未学習にならないようある程度は複雑なモデルを考えなければいけないが、過学習にならないように注意する。

汎化性能を検証する方法としてホールドアウト法があるが、大量の学習データが必要であり、かつ検証データを選択する際に特徴的なデータが偏らないよう注意する必要がある。別の方法としてクロスバリデーション（交差検証）がある。

モデルの学習・評価に使用するデータを学習データと検証データに分けるのはホールドアウト法と同じだが、クロスバリデーションでは全てのデータを一度は検証データとして扱うのでデータの偏りがあった際も検証できる。
あるモデルに対してクロスバリデーションをn回（n個のグループに分けている）した際、検証データを用いた各回の**精度の平均値**をそのモデルの精度として評価する。

## ハイパーパラメータの探索（グリッドサーチ）
学習モデルに採用するアルゴリズムによっては重みや説明変数の他にハイパーパラメータと呼ばれる値があり、この値によっても精度が変動するのでどの値が良いかを決めなければならない。

ただ、ハイパーパラメータが取りうる実数値を全て探索することは現実的に不可能なので、一定の間隔ごと（指数など）に値を決めて探索する。

アルゴリズムによってはハイパーパラメータの数が複数存在することもあるので、最適な評価を得られるパラメータにチューニングする必要がある。

# 第3章 ロジスティック回帰モデル
# 第4章 主成分分析
# 第5章 アルゴリズム
# 第6章 サポートベクターマシーン
