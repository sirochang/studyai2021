# Section1:強化学習
## 強化学習とは
長期的に「報酬」を最大化できるように「環境」の中で「行動」を選択できる「エージェント」を作ることを目標とする機械学習の一分野である。

## 強化学習の応用例
マーケティングの例

* 環境： 会社の販売促進部
* エージェント：プロフィールと購入履歴に基づいて、キャンペーンメールを送る顧客を決めるソフトウェア
  * 行動：顧客ごとに送信・非送信の二つの行動を選ぶ
  * 報酬：負の報酬（キャンペーンのコスト）と正の報酬（キャンペーンで生み出されると推測される売り上げ）を受ける

## 探索と利用のトレードオフ
環境において事前に完璧な知識があれば、最適な行動を予測し決定することは可能だが、強化学習の場合はこれが成り立たず、不完全な知識を元に行動しながらデータを収集し、最適な行動を見つけていくことになる。

下記はトレードオフの関係にある。
* 探索が足りない状態
  * 過去のデータでベストとされる行動のみを常に取り続ければ、他にもっとベストな行動があったとしても見つけれない
* 利用が足りない状態
  * 未知の行動のみを常に取り続ければ、過去の経験が活かせない

## 強化学習の差分
教師あり・なし学習との差分は目標が違うことが挙げられる。
* 教師あり・なし学習
  * データに含まれるパターンを見つけ出す、そのデータから未知のデータを予測する
* 強化学習
  * 優れた方策を見つけ出す

研究は昔から行われていたが、計算速度の観点からあまり実用化されなかった（教師あり・なし学習より計算コストがかかりがち）。近年は計算速度の進展や、下記の手法を組み合わせる手法により実用化が進んでいる。

* Q学習
  * 行動価値関数を、行動をするごとに更新することにより学習を進める
* 関数近似法
  * 価値関数や方策関数を関数近似する（ニューラルネットワークを利用できる）

## 行動価値関数
下記の2つ。

* 状態価値関数
  * ある状態の価値に注目する
* 行動価値関数
  * ある状態である行動を取った時の価値に注目する

## 方策関数
方策ベースの強化学習において、ある状態でどのような行動を採るのかの確率を与える関数である。

## 方策勾配法
方策反復法：方策をモデル化して最適化する手法→方策勾配法。基本的な形は勾配降下法の更新式に似ているが、損失の勾配を減算していたのに対し、Jを加算していることに注意

```
θ^(t+1) = θ^t + ε∇J(θ)
```

Jは収益を表すもので、平均報酬や割引報酬和の定義に対して行動価値関数を定義し、方策勾配定理が成り立つので ∇J(θ)を導き出せるらしい。

# Section2:AlphaGo
## Alpha Go Lee
* PolicyNet：方策関数を学習させる
* ValueNet：行動価値関数を学習させる
入力データは19*19（盤面）*48or49チャンネルで、どちらもCNNで、PolicyNetは二次元データのままSoftMaxで確率を、ValuNetは勝率を得るために全結合を行なって出力する。

AlphaGoの学習
* 教師あり学習によるRollOutPolicyとPolicyNetの学習
  * 強化学習を早く効率よく学習させるために、事前に教師あり学習を行なっておく。さらに計算量が少ないRollOutPolicyも学習させておく
* 強化学習によるPolicyNetの学習
* 強化学習によるValueNetの学習
  * モンテカルロ木探索を用いて学習する（このときRollOutPolicyを使える）

## Alpha Go Zero
AlphaGoLeeとの違い
* 教師あり学習を一切行わず、強化学習のみ
* 特徴入力からヒューリスティックな要素を排除（17チャンネル）
* PolicyNetとValueNetを一つのネットワークに結合した
* Residual Networkを導入した
* モンテカルロ木探索からRollOutシミュレーションをなくした

Residual Networkのメリット
* ネットワークにショートカット構造を追加して、勾配爆発や勾配消失が起きにくくなる
* 階層が違うネットワークのアンサンブル効果のようなものを得ることができる
* Convolution→BatchNorm→ReLU→Convolution→BatchNorm→Add→ReLU

派生系
* Bottleneck
  * 1×1KernelのConvolutionを利用し、1層目で次元削減を行って3層目で次元を復元する３層構造にする
  * ２層のものと比べて計算量はほぼ同じだが１層増やせるメリットがある
* PreActivation
  * BatchNorm→ReLU→Convolution→BatchNorm→ReLU→Convolution→Add
  * 畳み込みの前に活性化層を配置
* WideResNet
  * ConvolutionのFilter数をk倍にしたResNet。段階的に幅を増やしていくのが一般的
  * Filter数を増やすことにより、浅い層数でも深い層数のものと同等以上の精度となる
  * GPUをより効率的に使用できるため学習が早い
  * BatchNorm→ReLU→Convolution→BatchNorm→ReLU→dropout→Convolution→Add
* PyramidNet
  * WideResNetの課題として、幅が広がった直後の層に過度の負担がかかり精度を落とすと考えた
  * 段階的にではなく、各層でFilter数を増やしていくResNet
  * BatchNorm→Convolution→BatchNorm→ReLU→Convolution→BatchNorm→Add

# Section3:軽量化・高速化技術
深層学習とは多くのデータを使用したり、パラメータ調整のために多くの時間を使用したりするため、高速な計算が求められる。複数の計算資源を使用し、並列的にニューラルネットワークを構成することで、効率の良い学習を行いたい。

## データ並列
親モデルを各ワーカーに子モデルとしてコピーし、データを分割して各ワーカーごとに計算させる。

* 同期型
  * 各ワーカーが計算が終わるのを待ち、全ワーカーの勾配が出たところで勾配の平均を計算し、親モデルのパラメータを更新する
  * 学習が安定する（非同期型は最新のモデルのパラメータを利用できないので学習が不安定になりやすい）
  * 現在の主流
* 非同期型
  * 各ワーカーはお互いの計算を待たず、各子モデルごとに更新を行う。学習が終わった子モデルはパラメータサーバにpushされ、新たに学習を始める際は、パラメータサーバからpopしたモデルに対して学習していく
  * 同期型より処理速度は早い
  
## モデル並列
親モデルを各ワーカーに分割し、それぞれのモデルを学習させる。全てのデータで学習が終わった後で、一つのモデルへ復元する。モデルのパラメータ数が多いほどスピードアップの効率も上がる。枝分かれするニューラルネットワークで、枝分かれ部分を並列に学習させるなどの使い方が多い。

モデルが大きい時はモデル並列化、データが大きい時はデータ並列化をすると良い。

## GPU
GPGPUはGeneral-purpose on GPUの略で、元々の使用目的であるグラフィック以外の用途で使用されるGPUの総称である。

GPUはCPUと比べて、比較的低性能なコアが多数含まれており、簡単な並列処理が得意である。ニューラルネットワークの学習は単純な行列計算が多いので、GPUを利用することで高速化が可能である。

GPGPUの開発環境
* CUDA
  * GPU上で並列コンピューティングを行うためのプラットフォーム
  * NVIDIA社が開発しているGPUのみで使用可能
  * DeepLearning用に提供されているので使いやすい
* OpenCL
  * オープンな並列コンピューティングのプラットフォーム
  * NVIDIA社以外の会社（Intel, AMD, ARMなど）のGPUからでも使用可能
  * DeepLearning用の計算に特化しているわけではない

## モデルの軽量化
モデルの精度を維持しつつ、パラメータや演算回数を低減する手法の総称。

モバイルやIoT機器はパソコンに比べ性能が大きく劣る（主に計算速度と搭載メモリ）ため、モデルの軽量化は有用な手法である。

* 量子化：重みの精度を下げることにより、計算の高速化と省メモリ化を行う技術
* 蒸留：複雑で精度の良い教師モデルから軽量な生徒モデルを効率よく学習を行う技術
* プルーニング：寄与の少ないニューロンをモデルから削減し高速化と省メモリ化を行う技術

## 量子化
ネットワークが大きくなると大量のパラメータが必要となり学習や推論に多くのメモリと演算処理が必要となる。そこで通常のパラメータの 64bit 浮動小数点を 32bit など下位の精度に落とすことでメモリと演算処理の削減を行うこと。

メリデメ
* メリット
  * 計算の高速化：倍精度演算（64bit）と単精度演算（32bit）の演算は、NVIDIA社のGPUで比較しても2倍ぐらいの差があり、単精度演算の方が多く処理できる。
  * 省メモリ化：ニューロンの重みにかけるメモリサイズを下げるべく、浮動小数点数のbit数を少なくして有効桁数を下げる。
* デメリット
  * 精度の低下：ニューロンが表現できる有効桁が小さくなるとモデルの表現力も低下する。ただし、倍精度を単精度にしてもほぼ精度は変わらないことがわかっている。

## 蒸留
精度の高いモデルはニューロンの規模が大きなモデルになっている。そのため、推論に多くのメモリと演算処理が必要となる。そこで、規模の大きなモデルの知識を使って、軽量なモデルを作成する。

* 教師モデル：予測精度の高い、複雑なモデルやアンサンブルされたモデル
* 生徒モデル：教師モデルを元に作られた軽量なモデル

学習の仕方は、教師モデルと生徒モデルのそれぞれの誤差を使い、教師モデルの重みを固定して生徒モデルの重みのみを更新していく。

同程度の構成のモデルを学習する際、一から学習させるより蒸留で学習したモデルの方が精度が高くなることがわかっている。

## プルーニング
ネットワークが大きくなるとパラメータが大量になるが、全てのニューロンの計算が精度に寄与しているわけではない。つまり、モデルの精度に寄与が少ないニューロンを削除することでモデルの軽量化、高速化が見込まれる。

ニューロンの削除手法は、重みが閾値以下の場合にニューロンを削除し、再学習を行う。

一般的にニューロンを削除していくほどモデルは軽量化・高速化できるがその分精度は下がってしまう。ただし、ニューロンの数を元の半分に減らしても精度は9割強、ほとんど減らしても（1割以下）精度は9割弱ぐらいになるケースも確認されている。

# Section4:応用モデル
# Section5:Transformer
# Section6:物体検知・セグメンテーション
