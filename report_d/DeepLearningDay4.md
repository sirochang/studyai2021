# Section1:強化学習
## 強化学習とは
長期的に「報酬」を最大化できるように「環境」の中で「行動」を選択できる「エージェント」を作ることを目標とする機械学習の一分野である。

## 強化学習の応用例
マーケティングの例

* 環境： 会社の販売促進部
* エージェント：プロフィールと購入履歴に基づいて、キャンペーンメールを送る顧客を決めるソフトウェア
  * 行動：顧客ごとに送信・非送信の二つの行動を選ぶ
  * 報酬：負の報酬（キャンペーンのコスト）と正の報酬（キャンペーンで生み出されると推測される売り上げ）を受ける

## 探索と利用のトレードオフ
環境において事前に完璧な知識があれば、最適な行動を予測し決定することは可能だが、強化学習の場合はこれが成り立たず、不完全な知識を元に行動しながらデータを収集し、最適な行動を見つけていくことになる。

下記はトレードオフの関係にある。
* 探索が足りない状態
  * 過去のデータでベストとされる行動のみを常に取り続ければ、他にもっとベストな行動があったとしても見つけれない
* 利用が足りない状態
  * 未知の行動のみを常に取り続ければ、過去の経験が活かせない

## 強化学習の差分
教師あり・なし学習との差分は目標が違うことが挙げられる。
* 教師あり・なし学習
  * データに含まれるパターンを見つけ出す、そのデータから未知のデータを予測する
* 強化学習
  * 優れた方策を見つけ出す

研究は昔から行われていたが、計算速度の観点からあまり実用化されなかった（教師あり・なし学習より計算コストがかかりがち）。近年は計算速度の進展や、下記の手法を組み合わせる手法により実用化が進んでいる。

* Q学習
  * 行動価値関数を、行動をするごとに更新することにより学習を進める
* 関数近似法
  * 価値関数や方策関数を関数近似する（ニューラルネットワークを利用できる）

## 行動価値関数
下記の2つ。

* 状態価値関数
  * ある状態の価値に注目する
* 行動価値関数
  * ある状態である行動を取った時の価値に注目する

## 方策関数
方策ベースの強化学習において、ある状態でどのような行動を採るのかの確率を与える関数である。

## 方策勾配法
方策反復法：方策をモデル化して最適化する手法→方策勾配法。基本的な形は勾配降下法の更新式に似ているが、損失の勾配を減算していたのに対し、Jを加算していることに注意

```
θ^(t+1) = θ^t + ε∇J(θ)
```

Jは収益を表すもので、平均報酬や割引報酬和の定義に対して行動価値関数を定義し、方策勾配定理が成り立つので ∇J(θ)を導き出せるらしい。

# Section2:AlphaGo
## Alpha Go Lee
* PolicyNet：方策関数を学習させる
* ValueNet：行動価値関数を学習させる
入力データは19*19（盤面）*48or49チャンネルで、どちらもCNNで、PolicyNetは二次元データのままSoftMaxで確率を、ValuNetは勝率を得るために全結合を行なって出力する。

AlphaGoの学習
* 教師あり学習によるRollOutPolicyとPolicyNetの学習
  * 強化学習を早く効率よく学習させるために、事前に教師あり学習を行なっておく。さらに計算量が少ないRollOutPolicyも学習させておく
* 強化学習によるPolicyNetの学習
* 強化学習によるValueNetの学習
  * モンテカルロ木探索を用いて学習する（このときRollOutPolicyを使える）

## Alpha Go Zero
AlphaGoLeeとの違い
* 教師あり学習を一切行わず、強化学習のみ
* 特徴入力からヒューリスティックな要素を排除（17チャンネル）
* PolicyNetとValueNetを一つのネットワークに結合した
* Residual Networkを導入した
* モンテカルロ木探索からRollOutシミュレーションをなくした

Residual Networkのメリット
* ネットワークにショートカット構造を追加して、勾配爆発や勾配消失が起きにくくなる
* 階層が違うネットワークのアンサンブル効果のようなものを得ることができる
* Convolution→BatchNorm→ReLU→Convolution→BatchNorm→Add→ReLU

派生系
* Bottleneck
  * 1×1KernelのConvolutionを利用し、1層目で次元削減を行って3層目で次元を復元する３層構造にする
  * ２層のものと比べて計算量はほぼ同じだが１層増やせるメリットがある
* PreActivation
  * BatchNorm→ReLU→Convolution→BatchNorm→ReLU→Convolution→Add
  * 畳み込みの前に活性化層を配置
* WideResNet
  * ConvolutionのFilter数をk倍にしたResNet。段階的に幅を増やしていくのが一般的
  * Filter数を増やすことにより、浅い層数でも深い層数のものと同等以上の精度となる
  * GPUをより効率的に使用できるため学習が早い
  * BatchNorm→ReLU→Convolution→BatchNorm→ReLU→dropout→Convolution→Add
* PyramidNet
  * WideResNetの課題として、幅が広がった直後の層に過度の負担がかかり精度を落とすと考えた
  * 段階的にではなく、各層でFilter数を増やしていくResNet
  * BatchNorm→Convolution→BatchNorm→ReLU→Convolution→BatchNorm→Add

# Section3:軽量化・高速化技術
深層学習とは多くのデータを使用したり、パラメータ調整のために多くの時間を使用したりするため、高速な計算が求められる。複数の計算資源を使用し、並列的にニューラルネットワークを構成することで、効率の良い学習を行いたい。

## データ並列
親モデルを各ワーカーに子モデルとしてコピーし、データを分割して各ワーカーごとに計算させる。

* 同期型
  * 各ワーカーが計算が終わるのを待ち、全ワーカーの勾配が出たところで勾配の平均を計算し、親モデルのパラメータを更新する
  * 学習が安定する（非同期型は最新のモデルのパラメータを利用できないので学習が不安定になりやすい）
  * 現在の主流
* 非同期型
  * 各ワーカーはお互いの計算を待たず、各子モデルごとに更新を行う。学習が終わった子モデルはパラメータサーバにpushされ、新たに学習を始める際は、パラメータサーバからpopしたモデルに対して学習していく
  * 同期型より処理速度は早い
  
## モデル並列
親モデルを各ワーカーに分割し、それぞれのモデルを学習させる。全てのデータで学習が終わった後で、一つのモデルへ復元する。モデルのパラメータ数が多いほどスピードアップの効率も上がる。枝分かれするニューラルネットワークで、枝分かれ部分を並列に学習させるなどの使い方が多い。

モデルが大きい時はモデル並列化、データが大きい時はデータ並列化をすると良い。

## GPU
GPGPUはGeneral-purpose on GPUの略で、元々の使用目的であるグラフィック以外の用途で使用されるGPUの総称である。

GPUはCPUと比べて、比較的低性能なコアが多数含まれており、簡単な並列処理が得意である。ニューラルネットワークの学習は単純な行列計算が多いので、GPUを利用することで高速化が可能である。

GPGPUの開発環境
* CUDA
  * GPU上で並列コンピューティングを行うためのプラットフォーム
  * NVIDIA社が開発しているGPUのみで使用可能
  * DeepLearning用に提供されているので使いやすい
* OpenCL
  * オープンな並列コンピューティングのプラットフォーム
  * NVIDIA社以外の会社（Intel, AMD, ARMなど）のGPUからでも使用可能
  * DeepLearning用の計算に特化しているわけではない

## モデルの軽量化
モデルの精度を維持しつつ、パラメータや演算回数を低減する手法の総称。

モバイルやIoT機器はパソコンに比べ性能が大きく劣る（主に計算速度と搭載メモリ）ため、モデルの軽量化は有用な手法である。

* 量子化：重みの精度を下げることにより、計算の高速化と省メモリ化を行う技術
* 蒸留：複雑で精度の良い教師モデルから軽量な生徒モデルを効率よく学習を行う技術
* プルーニング：寄与の少ないニューロンをモデルから削減し高速化と省メモリ化を行う技術

## 量子化
ネットワークが大きくなると大量のパラメータが必要となり学習や推論に多くのメモリと演算処理が必要となる。そこで通常のパラメータの 64bit 浮動小数点を 32bit など下位の精度に落とすことでメモリと演算処理の削減を行うこと。

メリデメ
* メリット
  * 計算の高速化：倍精度演算（64bit）と単精度演算（32bit）の演算は、NVIDIA社のGPUで比較しても2倍ぐらいの差があり、単精度演算の方が多く処理できる。
  * 省メモリ化：ニューロンの重みにかけるメモリサイズを下げるべく、浮動小数点数のbit数を少なくして有効桁数を下げる。
* デメリット
  * 精度の低下：ニューロンが表現できる有効桁が小さくなるとモデルの表現力も低下する。ただし、倍精度を単精度にしてもほぼ精度は変わらないことがわかっている。

## 蒸留
精度の高いモデルはニューロンの規模が大きなモデルになっている。そのため、推論に多くのメモリと演算処理が必要となる。そこで、規模の大きなモデルの知識を使って、軽量なモデルを作成する。

* 教師モデル：予測精度の高い、複雑なモデルやアンサンブルされたモデル
* 生徒モデル：教師モデルを元に作られた軽量なモデル

学習の仕方は、教師モデルと生徒モデルのそれぞれの誤差を使い、教師モデルの重みを固定して生徒モデルの重みのみを更新していく。

同程度の構成のモデルを学習する際、一から学習させるより蒸留で学習したモデルの方が精度が高くなることがわかっている。

## プルーニング
ネットワークが大きくなるとパラメータが大量になるが、全てのニューロンの計算が精度に寄与しているわけではない。つまり、モデルの精度に寄与が少ないニューロンを削除することでモデルの軽量化、高速化が見込まれる。

ニューロンの削除手法は、重みが閾値以下の場合にニューロンを削除し、再学習を行う。

一般的にニューロンを削除していくほどモデルは軽量化・高速化できるがその分精度は下がってしまう。ただし、ニューロンの数を元の半分に減らしても精度は9割強、ほとんど減らしても（1割以下）精度は9割弱ぐらいになるケースも確認されている。

# Section4:応用モデル
ディープラーニングモデルは精度は良いが、ネットワークが深くなり計算量が増え、多くの計算リソースが必要となる。そこで、ディープラーニングモデルの軽量化・高速化および高精度化の実現を目指す。

## MobileNet
近年の画像認識タスクに用いられる最新のニューラルネットワークは、多くのモバイルや組み込みアプリケーションの実行環境を上回る高い計算資源を必要とする。

画像認識タスクに用いられるニューラルネットワークで用いられる一般的な畳み込みレイヤーは計算量が多いので、MobileNetは「Depthwise Convolution」と「Pointwise Convolution」の組み合わせで軽量化を実現する。

* 入力特徴マップ：H * W
* チャネル数：C
* 畳み込みカーネルのサイズ：K * K
* 出力チャネル数：M

ストライド1でパディングを適用した際の畳み込み計算の計算量は
＊　一般的な畳み込みレイヤー： K * K * C * M * H * W
  * 空間方向とチャネル方向の計算を同時に行う
* MobileNet: (Depthwise Convの計算量) + (Pointwise Convの計算量) = (K * K * H * W * C) + (C * M * H * W)
  * Depthwise Conv： チャネルごとに空間方向に畳み込みを行う
  * Pointwise Conv: チャネル方向に畳み込む

## DenseNet
DenseConvolutionalNetworkはCNNアーキテクチャの一種である。ニューラルネットワークでは層が深くなるにつれ学習が難しくなるという問題があったが、ResNetなどでは前方の層から後方の層へアイデンティティ接続を介してパスを作ることで問題を対処した。DenseNetも似たようなアーキテクチャで、DenseBlockというモジュールを用いる。

DenseNetは、「初期の畳み込み」、「DenseBlock」、「変換レイヤー」、「判別レイヤー」から構成される。

* DenseBlock
  * 出力層に前の層の入力を足し合わせる
  * 層間の情報の伝達を最大にするためにブロック内の全ての同特徴量サイズの層を結合する
  * growth rateによってどれだけ伝達していくかを決めるハイパーパラメータだが、大きくしすぎないよう注意する
* 変換レイヤー
  * 特徴マップのサイズを変更する
  * DenseBlockで増えたサイズをダウンサンプリングし、DenseBlockをつなぐ役割を果たす

DenseNetとResNetの違い
* DenseBlock：前方の各層からの出力全てが後方の層への入力として用いられる
* RessidualBlock：前1層の入力のみ後方の層へ入力

## Layer正規化/Instance正規化
レイヤー間を流れるデータ分布をミニバッチ単位で平均0で分散1になるよう正規化する手法で、学習時間の短縮や初期値への依存低減、過学習の抑制などの効果がある。
しかし、実行環境の違いによってはミニバッチ数を変えざるをえなく、ミニバッチ数が小さいと効果を発揮できないことがある。

* BatchNorm
  * ミニバッチに含まれるsampleの同一チャンネルが同一分布に従うよう正規化
* LayerNorm
  * それぞれのsampleの全てのpixelsが同一分布に従うよう正規化
  * 入力データのシフトや重み行列のスケールやシフトに対してロバスト
* InstanceNorm
  * さらにチャンネルも同一分布に従うよう正規化
  * コントラストの正規化に寄与・画像のスタイル転送やテクスチャ合成タスクなどで利用される

論理的に考えるとBatchNormの用にミニバッチに対して同一チャンネルで正規化するべきだが、同一sampleに対しての正規化やさらにチャンネルも限定して正規化しても結果としてはうまく学習できることがわかった。

## Wavenet
時系列データに対してDilatedConvolutionという結合確率を効率的に学習できるようにしたCNNを適用する。

通常であれば各時刻のデータを次時刻のデータへ伝達させていくのだが、DilatedConvolutionでは層が深くなるにつれて畳み込む時刻を離すことが特徴で、パラメータ数に対する受容野を広げることができる。

# Section5:Transformer
# Section6:物体検知・セグメンテーション
物体認識タスクとして主に下記の4つあり、それぞれ出力が異なる。入力はカラー・モノクロ問わない画像。
* 分類：画像に対し単一または複数のクラスラベル
* 物体検知：Bounding Box
* 意味領域分割：各ピクセルに対し単一のクラスラベル（インスタンスの区別なし）
* 個体領域分割：各ピクセルに対し単一のクラスラベル（インスタンスの区別あり）

## 代表的なデータセットについて
VOC12、ILSVRC17、MS COCO18、OICOD18など様々なデータセットを用いることがあるが、扱うクラス数やデータセット数、1画像あたりのBox数が異なるため、実現したいアプリケーションの目的によって学習に使うデータセットを選ぶ必要がある。

## 評価指標
分類問題ではConfusion Matrixで示される数値を用いて、Accuracy・Precision・Recall・F1scoreなどを指標に使うことが多い。

クラス分類ではconfidenceを変えてPrecisionやRecallの変化を見るが、物体検出の場合はconfidenceを変えるとそもそも出力数自体が異なってくることに注意する。

また物体検出ではクラスラベルだけではなく、物体位置の予測精度も合わせて評価したい。そこで用いられるのが IoU(Intersection over Union)で、Ground-Truth（正解）とprediction（予測）におけるUnionに対するIntersection（共通部分）の割合を指標とする。

クラスラベルを固定した時の、PR曲線の下側面積をAverage Precisionと呼び、さらに全クラスに拡張したものをmean Average precisionとして指標に用いる。

上記の検出精度に加えて、検出速度も考慮する必要があり、検出精度はFrames Per Secondやinference timeとのトレードオフになる。

## 物体検知
* 1段階検出器
  * 候補領域の検出とクラス推定を同時に行う
  * 相対的に精度は低い傾向
  * 相対的に計算量が小さく推論も早い傾向
* 2段階検出器
  * 候補領域の検出とクラス推定を別々に行う
  * 相対的に精度が高い傾向
  * 相対的に計算量が大きく推論も遅い傾向

### Single Shot Detector
VGG16をベースに、FC2層をConv層に変更（残る1つのFC層は削除）。

マルチスケール特徴マップを用いることがポイントで、VGG16の10層目に相当するConv層やVGG１６最後のConv層以降のそれぞれ異なる条件のConv層から得られる情報を用いる。
* 特徴マップのサイズ
* デフォルトマップの数

多数のデフォルトマップを用意することで生じる問題と対処
* Non-Maximum Suppression
  * 1つの物体検知に対して多数の異なるデフォルトマップを用意することになり、これは冗長である
  * デフォルトマップごとのIoUを計算し、閾値を超えているのであれば最大のデフォルトマップだけを残せば良い
* Hard Negative Mining
  * 背景も1クラスとして扱うので、出力結果のデフォルトマップのうち背景クラスが占める割合が大きくなってしまう
  * 背景クラス数が検知したいクラス数の3倍より多くのデフォルトマップを出力しないようにする

損失関数としては、分類問題と同じようにconfidenceに対する損失に加え、検出位置に対する損失も考慮する。

## Semantic Segmentation
画像認識において、ある程度のブロックを対象にしたい場合、対象の受容野を広げていく必要があり、Convolution層を重ねていくか、プーリングとストライドを行うか、Convolution層で受容野を広げる（Dilated Convolution）必要がある。

### Deconvolution/Transposed Convolution
convolutionと同じように、カーネルサイズ、パディング、ストライドを設けて、小さな特徴マップから大きな特徴マップを作り出す。
ただし、ネットワーク前段のプーリングによって失われた情報がDeconvolutionで戻る訳ではない。

ただDeconvolutionをするだけでは低レイヤーのプーリングによって輪郭情報が失われているので、低レイヤーのプーリング層の出力をelement-wise additionすることで輪郭情報を保管しながら特徴マップのサイズを上げていく（アップサンプリングする）。

### unpooling
プーリングする際にプーリングした位置情報を保持しておき、アップサンプリングする際は保持しておいた位置に特徴マップを当てはめる。

### Dilated Convolution
Convolutionの段階で受容野を広げる工夫。

カーネルを使って畳み込む際、通常はストライドによって畳み込む領域を移していくが、加えて何マスかスキップさせて畳み込むことで、結果的に同じ大きさの領域を畳み込むのに必要な層数を減らすことができる。（Convolution層1つあたりの受容野を広げることができる）
